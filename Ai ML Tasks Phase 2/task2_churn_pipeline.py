# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15A8R9qqJJSRiEB98zv7mDBg7q5ceIOlK
"""

# ===============================
# 1️⃣ Libraries Install
# ===============================
!pip install -q scikit-learn pandas joblib

# ===============================
# 2️⃣ Imports
# ===============================
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report
import joblib

# ===============================
# 3️⃣ Load Dataset (Telco Churn)
# ===============================
# Colab me upload karne ke liye "Files" tab → upload CSV
df = pd.read_csv("Telco-Customer-Churn.csv")
print(df.head())

# ===============================
# 4️⃣ Preprocessing
# ===============================
# Identify numerical and categorical columns
numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
categorical_cols.remove('customerID')  # drop ID column
target_col = 'Churn'

# Convert target to binary
df[target_col] = df[target_col].apply(lambda x: 1 if x=='Yes' else 0)

# Fill missing values if any (example)
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)

# Features and target
X = df.drop(['customerID', target_col], axis=1)
y = df[target_col]

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ===============================
# 5️⃣ Preprocessing Pipeline
# ===============================
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_cols),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)
    ]
)

# ===============================
# 6️⃣ Full ML Pipeline
# ===============================
pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(random_state=42))
])

# ===============================
# 7️⃣ Hyperparameter Tuning
# ===============================
param_grid = {
    'classifier__n_estimators': [100, 200],
    'classifier__max_depth': [5, 10, None]
}

grid = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', n_jobs=-1)
grid.fit(X_train, y_train)

print("Best Parameters:", grid.best_params_)

# ===============================
# 8️⃣ Evaluate Model
# ===============================
y_pred = grid.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("F1 Score:", f1_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))

# ===============================
# 9️⃣ Save Pipeline
# ===============================
joblib.dump(grid.best_estimator_, "telco_churn_pipeline.pkl")
print("Pipeline saved as telco_churn_pipeline.pkl")